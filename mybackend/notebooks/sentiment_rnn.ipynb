{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7235569,"sourceType":"datasetVersion","datasetId":4189989},{"sourceId":40627787,"sourceType":"kernelVersion"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom nltk.corpus import stopwords \nfrom collections import Counter\nimport string\nimport re\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-31T12:07:01.102777Z","iopub.execute_input":"2024-07-31T12:07:01.103161Z","iopub.status.idle":"2024-07-31T12:07:04.064197Z","shell.execute_reply.started":"2024-07-31T12:07:01.103133Z","shell.execute_reply":"2024-07-31T12:07:04.063167Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/imdb-dataset-sentiment-analysis/IMDB_dataset.csv\")\nprint(data.head())\n\nfrom string import punctuation\ndef remove_punc(text):\n    text = text.lower()\n    return (\"\".join(i for i in text if i not in punctuation))\n\ndata[\"review\"] = data[\"review\"].apply(remove_punc)\nprint(data.head())\nX = data[\"review\"].values\ny = data[\"sentiment\"].values\nX_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y)\nprint(X_train.shape)\nprint(X_test.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:07:20.944622Z","iopub.execute_input":"2024-07-31T12:07:20.945633Z","iopub.status.idle":"2024-07-31T12:07:30.613569Z","shell.execute_reply.started":"2024-07-31T12:07:20.945599Z","shell.execute_reply":"2024-07-31T12:07:30.612648Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n                                              review sentiment\n0  one of the other reviewers has mentioned that ...  positive\n1  a wonderful little production br br the filmin...  positive\n2  i thought this was a wonderful way to spend ti...  positive\n3  basically theres a family where a little boy j...  negative\n4  petter matteis love in the time of money is a ...  positive\n(37500,)\n(12500,)\n","output_type":"stream"}]},{"cell_type":"code","source":"def process(string):\n    string = re.sub(r\"[^\\w\\s]\", '', string)\n    string = re.sub(r\"\\d\", '', string)\n    string = re.sub(r\"\\s+\", '', string)\n    return string\n\ndef tokenize(X_train,y_train,X_test,y_test):\n    words = []\n    stop_words = set(stopwords.words('english')) \n    for x in X_train:\n        for word in x.split():\n            word = process(word)\n            if word not in stop_words and word != '':\n                words.append(word)\n                \n    counts = Counter(words)\n    vocab = sorted(counts, key=counts.get, reverse=True)[:1000]\n    vocab_to_int = {word: ii for ii, word in enumerate(vocab,1)}\n    new_X_train = []\n    new_X_test = []\n    for s in X_train:\n            new_X_train.append([vocab_to_int[process(word)] for word in s.split() \n                                     if process(word) in vocab_to_int.keys()])\n    for s in X_test:\n            new_X_test.append([vocab_to_int[process(word)] for word in s.split() \n                                    if process(word) in vocab_to_int.keys()])\n            \n    new_y_train = [1 if label =='positive' else 0 for label in y_train]  \n    new_y_test = [1 if label =='positive' else 0 for label in y_test]\n    return new_X_train, new_y_train,new_X_test, new_y_test, vocab_to_int\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:07:45.599499Z","iopub.execute_input":"2024-07-31T12:07:45.600118Z","iopub.status.idle":"2024-07-31T12:07:45.610504Z","shell.execute_reply.started":"2024-07-31T12:07:45.600086Z","shell.execute_reply":"2024-07-31T12:07:45.609418Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_train,y_train,X_test,y_test,vocab_to_int = tokenize(X_train,y_train,X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:07:58.601676Z","iopub.execute_input":"2024-07-31T12:07:58.602049Z","iopub.status.idle":"2024-07-31T12:09:47.574386Z","shell.execute_reply.started":"2024-07-31T12:07:58.602021Z","shell.execute_reply":"2024-07-31T12:09:47.573326Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"'''\nnon_zero_idx_train = [ii for ii, review in enumerate(X_train) if len(review) != 0]\nnon_zero_idx_test = [ii for ii, review in enumerate(X_test) if len(review) != 0]\nX_train = [X_train[ii] for ii in non_zero_idx_train]\nX_test = [X_test[ii] for ii in non_zero_idx_test]\ny_train = np.array([y_train[ii] for ii in non_zero_idx_train])\ny_test = np.array([y_test[ii] for ii in non_zero_idx_test])\nprint(len(X_train), len(X_test))\n'''","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:30:36.894960Z","iopub.execute_input":"2024-07-08T10:30:36.895732Z","iopub.status.idle":"2024-07-08T10:30:36.933239Z","shell.execute_reply.started":"2024-07-08T10:30:36.895694Z","shell.execute_reply":"2024-07-08T10:30:36.932355Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"37499 12500\n","output_type":"stream"}]},{"cell_type":"code","source":"def padding(sentence, seqLength):\n    #determine shape\n    features = np.zeros((len(sentence), seqLength), dtype=int)\n    for i, row in enumerate(sentence):\n        if len(row) != 0:\n            features[i, -len(row):] = np.array(row)[:seqLength]\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:10:01.258913Z","iopub.execute_input":"2024-07-31T12:10:01.259265Z","iopub.status.idle":"2024-07-31T12:10:01.264855Z","shell.execute_reply.started":"2024-07-31T12:10:01.259237Z","shell.execute_reply":"2024-07-31T12:10:01.263939Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X_train_pad = padding(X_train,500)\nX_test_pad = padding(X_test,500)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:10:03.482069Z","iopub.execute_input":"2024-07-31T12:10:03.482808Z","iopub.status.idle":"2024-07-31T12:10:04.015897Z","shell.execute_reply.started":"2024-07-31T12:10:03.482777Z","shell.execute_reply":"2024-07-31T12:10:04.015084Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Tensor datasets\ntrain_data = TensorDataset(torch.from_numpy(X_train_pad), torch.from_numpy(np.array(y_train)))\nvalid_data = TensorDataset(torch.from_numpy(X_test_pad), torch.from_numpy(np.array(y_test)))\n\nbatch_size = 50\n\n#Shuffle for generalization\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\nvalid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n\n#Obtain a batch of the training data\ndataiter = iter(train_loader)\nsampleX, sampley = next(dataiter)\n\nprint('Sample input size: ', sampleX.size())\nprint('Sample input: \\n', sampleX)\nprint('Sample input: \\n', sampley)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:10:06.310060Z","iopub.execute_input":"2024-07-31T12:10:06.310419Z","iopub.status.idle":"2024-07-31T12:10:06.381935Z","shell.execute_reply.started":"2024-07-31T12:10:06.310390Z","shell.execute_reply":"2024-07-31T12:10:06.381040Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Sample input size:  torch.Size([50, 500])\nSample input: \n tensor([[  0,   0,   0,  ..., 551,   5, 137],\n        [  0,   0,   0,  ..., 380, 178, 215],\n        [  0,   0,   0,  ..., 100, 448, 165],\n        ...,\n        [  0,   0,   0,  ..., 709, 118,  39],\n        [  0,   0,   0,  ...,  76, 295, 531],\n        [  0,   0,   0,  ..., 254, 650,  45]])\nSample input: \n tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n        1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n        0, 0])\n","output_type":"stream"}]},{"cell_type":"code","source":"train_on_gpu=torch.cuda.is_available()\n\nif(train_on_gpu):\n    print('Training on GPU.')\nelse:\n    print('No GPU available, training on CPU.')","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:10:09.400301Z","iopub.execute_input":"2024-07-31T12:10:09.401032Z","iopub.status.idle":"2024-07-31T12:10:09.428701Z","shell.execute_reply.started":"2024-07-31T12:10:09.400998Z","shell.execute_reply":"2024-07-31T12:10:09.427801Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Training on GPU.\n","output_type":"stream"}]},{"cell_type":"code","source":"\nclass SentimentRNN(nn.Module):\n    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n        super(SentimentRNN,self).__init__()\n        self.output_dim = output_dim\n        self.hidden_dim = hidden_dim\n        self.no_layers = no_layers\n        self.vocab_size = vocab_size\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim, num_layers=no_layers, batch_first=True)\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(self.hidden_dim, output_dim)\n        self.sig = nn.Sigmoid()\n       \n    def forward(self,x,hidden):\n        batch_size = x.size(0)\n        embeds = self.embedding(x)\n        lstm_out, hidden = self.lstm(embeds, hidden)\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n        out = self.dropout(lstm_out)\n        out = self.fc(out)\n        sig_out = self.sig(out)\n        sig_out = sig_out.view(batch_size, -1)\n        sig_out = sig_out[:, -1]\n        return sig_out, hidden\n    \n    def init_hidden(self, batch_size):\n        #Hidden state\n        weight = next(self.parameters()).data\n        if (train_on_gpu):\n            hidden = (weight.new(self.no_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                  weight.new(self.no_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weight.new(self.no_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.no_layers, batch_size, self.hidden_dim).zero_())\n        \n        return hidden","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:10:11.600257Z","iopub.execute_input":"2024-07-31T12:10:11.600646Z","iopub.status.idle":"2024-07-31T12:10:11.612862Z","shell.execute_reply.started":"2024-07-31T12:10:11.600617Z","shell.execute_reply":"2024-07-31T12:10:11.611787Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"no_layers = 2\nvocab_size = len(vocab_to_int) + 1\nembedding_dim = 64\noutput_dim = 1\nhidden_dim = 256\n\nmodel = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:10:15.020525Z","iopub.execute_input":"2024-07-31T12:10:15.020905Z","iopub.status.idle":"2024-07-31T12:10:15.042543Z","shell.execute_reply.started":"2024-07-31T12:10:15.020873Z","shell.execute_reply":"2024-07-31T12:10:15.041643Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"SentimentRNN(\n  (embedding): Embedding(1001, 64)\n  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=256, out_features=1, bias=True)\n  (sig): Sigmoid()\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Training\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:10:18.978502Z","iopub.execute_input":"2024-07-31T12:10:18.979500Z","iopub.status.idle":"2024-07-31T12:10:20.087449Z","shell.execute_reply.started":"2024-07-31T12:10:18.979457Z","shell.execute_reply":"2024-07-31T12:10:20.085477Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"clip = 5\nepochs = 4 \n\ndef acc(pred,label):\n    pred = torch.round(pred.squeeze())\n    return torch.sum(pred == label.squeeze()).item()\n\nif(train_on_gpu):\n    model.cuda()\n    \nfor epoch in range(epochs):\n    train_losses = []\n    train_acc = 0.0\n    #train mode\n    model.train() \n    h = model.init_hidden(batch_size)\n    for inputs, labels in train_loader:\n        if(train_on_gpu):\n            inputs, labels = inputs.cuda(), labels.cuda()  \n        h = tuple([each.data for each in h])\n        model.zero_grad()\n        output,h = model(inputs,h)\n        loss = criterion(output.squeeze(), labels.float())\n        loss.backward()\n        train_losses.append(loss.item())\n        accuracy = acc(output,labels)\n        train_acc += accuracy\n        nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n\ntest_losses = []\nnum_correct = 0\n\nh = model.init_hidden(batch_size)\n#Testing mode\nmodel.eval()\nfor inputs, labels in valid_loader:\n    h = tuple([each.data for each in h])\n    if(train_on_gpu):\n        inputs, labels = inputs.cuda(), labels.cuda()\n    output, h = model(inputs, h)\n    test_loss = criterion(output.squeeze(), labels.float())\n    test_losses.append(test_loss.item())\n    pred = torch.round(output.squeeze()) \n    # compare predictions to true label\n    correct_tensor = pred.eq(labels.float().view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    num_correct += np.sum(correct)\n\nprint(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\ntest_acc = num_correct/len(valid_loader.dataset)\nprint(\"Test accuracy: {:.3f}\".format(test_acc))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:17:35.030852Z","iopub.execute_input":"2024-07-31T12:17:35.031546Z","iopub.status.idle":"2024-07-31T12:22:05.127981Z","shell.execute_reply.started":"2024-07-31T12:17:35.031516Z","shell.execute_reply":"2024-07-31T12:22:05.126912Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Test loss: 0.464\nTest accuracy: 0.847\n","output_type":"stream"}]},{"cell_type":"code","source":"h = model.init_hidden(50)\nh = tuple(each.data for each in h)\nprint(h)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:22:11.714862Z","iopub.execute_input":"2024-07-31T12:22:11.715228Z","iopub.status.idle":"2024-07-31T12:22:11.764674Z","shell.execute_reply.started":"2024-07-31T12:22:11.715196Z","shell.execute_reply":"2024-07-31T12:22:11.763757Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nimport pandas as pd\nimport nltk\nnltk.download(\"stopwords\")\n\nclass Scraper:\n    def __init__(self,url):\n        self.url = url\n        \n    def getText(self):\n        response = requests.get(self.url)\n        html_data = BeautifulSoup(response.content, \"html.parser\")\n        text = html_data.get_text()\n        words = text.split()\n        words = [word.lower() for word in words if word.isalpha()]\n        return ' '.join(words)\n    \nclass ETL:\n    def __init__(self,url):\n        self.url = url\n    \n    def run(self):\n        scrape = Scraper(self.url)\n        text = scrape.getText()\n        return text\n    \nif __name__ == \"__main__\":\n    url = \"https://www.imdb.com/title/tt9486184/reviews\"\n    pipeline = ETL(url)\n    test_review = pipeline.run()\n    print(test_review)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:22:17.299843Z","iopub.execute_input":"2024-07-31T12:22:17.300198Z","iopub.status.idle":"2024-07-31T12:22:18.516346Z","shell.execute_reply.started":"2024-07-31T12:22:17.300169Z","shell.execute_reply":"2024-07-31T12:22:18.515462Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\npositive positive user reviews imdb menumoviesrelease calendartop moviesmost popular moviesbrowse movies by genretop box officeshowtimes ticketsmovie newsindia movie spotlighttv on tv streamingtop tv showsmost popular tv showsbrowse tv shows by genretv newswatchwhat to watchlatest trailersimdb originalsimdb picksimdb spotlightimdb podcastsawards eventsoscarsemmystifffestival seasonstarmeter awardsawards centralall eventscelebsborn todaymost popular celebscelebrity newscommunityhelp centercontributor zonepollsfor industry professionalslanguageenglish supportedenglish supportedfrançais inenfully supportedenglish supportedfrançais app positive user reviews review this title reviews hide spoilers sort featured review date total votes prolific reviewer review rating filter by show all star stars stars stars stars stars stars stars stars stars positive effort may i can see what they were trying to pull off and they almost did emma paunil and brianna roy have a lot of experience between but there is potential for both of their this venture however fell just a little short of being a complete effort mostly it was the sound that had me up until the party it was there was an tinny sound happening throughout until i know why the sound engineers clue into it until that party offbeat and story line kept me entertained enough to get through the sound it fell off the rails a bit during the party was it too much to ask for the solo cups to at least appear filled with any sort of aside from establishing an the whole scene felt it was a good venture for a crew with limited out of found this was this review sign in to permalink horrible script with mediocre acting may this was so bad i finish the actresses are so bad at acting it feels like a bad comedy from minute the high rated reviews is obviously from and is pure out of found this was this review sign in to permalink reviews from friends always make me may this movie is absolutely the script and production are all there is actually nothing redeemable about in fact if my friend was in this instead of giving it a perfect stop being friends with how bad it you have been warned do not waste your time on this out of found this was this review sign in to permalink not funny may this is a very stupid movie that is so not it deserve out of found this was this review sign in to permalink quite entertaining may worth watching first time for the second time to absorb some of the sharp by some of the reviews on here say you probably have to be over the age of and an iq above to appreciate some of the or the reviewrs just like releasing some of their angst interesting to note that the most liked a was given by someone with form your own conclusions about roy has a bit of a reese witherspoon thing going on about out of found this was this review sign in to permalink horrible august i wanted to like this i really but the thing is there is absolutely nothing to like about it not the acting is the plot is nonexistent and just nothing about this movie even makes waste your time with this out of found this was this review sign in to permalink hilarious and cute may i thought the cast was brianna and emma were exceptionaly talented in thier fun out of found this was this review sign in to permalink actress kyleigh amazing credit march the actress kyleigh bakker who plays the role as kylie is a well known friend of mine from school and she is extremely talented from singing and of course at school she slayed theater class like it was and i hope to see more of her and her i know that grow to do big things leading to awards and huge audiences shouting her and definitely be there every step of the congratulations kyleigh you earned everything coming to you out of found this was this review sign in to permalink see also awards faq user ratings external reviews metacritic reviews positive opinion awards faq user reviews user ratings external reviews metacritic reviews details full cast and crew release dates official sites company credits filming production technical specs storyline taglines plot summary synopsis plot keywords parents guide did you trivia goofs crazy credits quotes alternate versions connections soundtracks photo video photo gallery trailers and videos related items news showtimes external sites explore more show less create a list user lists related lists from imdb users failing movies on movie galaxy a list of titles created may downloaded movies a list of titles created sep see all related lists share this clear your history recently viewed get the imdb appsign in for more accesssign in for more accessget the imdb apphelpsite indeximdbprobox office mojolicense imdb datapress roomadvertisingjobsconditions of useprivacy policyyour ads privacy an amazon by\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef tokenize_review(test_review):\n    test_review = test_review.lower()\n    test_text = ''.join([i for i in test_review if i not in punctuation])\n    test_words = test_text.split()\n    test_ints = []\n    test_ints.append([vocab_to_int.get(word, 0) for word in test_words])\n    return test_ints\n\ndef predict(net, test_review, sequence_length=500):\n    model.eval()\n    test_ints = tokenize_review(test_review)\n    seq_length=sequence_length\n    features = padding(test_ints, seq_length)\n    feature_tensor = torch.from_numpy(features)\n    batch_size = feature_tensor.size(0)\n    h = net.init_hidden(batch_size)\n    if(train_on_gpu):\n        feature_tensor = feature_tensor.cuda()\n    output, h = model(feature_tensor, h)\n    print('Prediction value: {:.6f}'.format(output.item()))\n    if(output.item() > 0.5):\n        print(\"Positive review detected! With probability of:\",output.item())\n    else:\n        print(\"Negative review detected! With probability of:\", (1 - output.item()))\n        \n#test_review = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'\npredict(model, test_review, 500)        ","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:22:34.203044Z","iopub.execute_input":"2024-07-31T12:22:34.203860Z","iopub.status.idle":"2024-07-31T12:22:34.235270Z","shell.execute_reply.started":"2024-07-31T12:22:34.203816Z","shell.execute_reply":"2024-07-31T12:22:34.234235Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Prediction value: 0.235779\nNegative review detected! With probability of: 0.7642206698656082\n","output_type":"stream"}]},{"cell_type":"code","source":"#Deploying PyTorch using Tracing Method\n'''\nimport torch\nclass SentimentRNN(nn.Module):\n    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n        super(SentimentRNN,self).__init__()\n        self.output_dim = output_dim\n        self.hidden_dim = hidden_dim\n        self.no_layers = no_layers\n        self.vocab_size = vocab_size\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim, num_layers=no_layers, batch_first=True)\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(self.hidden_dim, output_dim)\n        self.sig = nn.Sigmoid()\n    \n    def forward(self,x,hidden):\n        batch_size = x.size(0)\n        embeds = self.embedding(x)\n        lstm_out, hidden = self.lstm(embeds, hidden)\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n        out = self.dropout(lstm_out)\n        out = self.fc(out)\n        sig_out = self.sig(out)\n        sig_out = sig_out.view(batch_size, -1)\n        sig_out = sig_out[:, -1]\n        return sig_out, hidden\n    \n    def init_hidden(self, batch_size):\n        #Hidden state\n        weight = next(self.parameters()).data\n        if (train_on_gpu):\n            hidden = (weight.new(self.no_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                  weight.new(self.no_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weight.new(self.no_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.no_layers, batch_size, self.hidden_dim).zero_())\n        \n        return hidden\n'''\nexample = torch.zeros(50,500, dtype = torch.int)\nif train_on_gpu:\n    example = example.cuda()\nprint(example)\n\ntraced_script_module = torch.jit.trace(model, (example,h))\ntraced_script_module.save(\"sentiment_rnn.pt\")\nnew_model = torch.jit.load(\"sentiment_rnn.pt\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T12:23:06.770531Z","iopub.execute_input":"2024-07-31T12:23:06.771015Z","iopub.status.idle":"2024-07-31T12:23:07.095504Z","shell.execute_reply.started":"2024-07-31T12:23:06.770981Z","shell.execute_reply":"2024-07-31T12:23:07.094598Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"tensor([[0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        ...,\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0', dtype=torch.int32)\n","output_type":"stream"}]}]}
